{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNE : From raw data to epochs and evoked responses (ERF/ERP)\n",
    "\n",
    "`\n",
    "Authors:\n",
    "Britta Westner, Alexandre Gramfort, Denis A. Engemann\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We start out with loading the packages we need. These include `matplotlib` for plotting, `os` for path management, `numpy` for numerical computations, and of course `mne`:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import mne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's double check your MNE-Python version. This should give back 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.dev0'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mne.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the log-level of MNE-Python to 'warning' so the output is less verbose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.set_log_level('warning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Help!\n",
    "\n",
    "Remember, if you need help just ask ... the machine!\n",
    "Let's see how to get the docstring information for a function - here, the function `pick_types`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mmne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpick_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmeg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0meeg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0meog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mecg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0memg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mref_meg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmisc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mresp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mchpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mexci\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msyst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mseeg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdipole\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mgof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mecog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfnirs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcsd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mgsr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bads'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mselection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Pick channels by type and names.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "\n",
      "info : mne.Info\n",
      "    The :class:`mne.Info` object with information about the sensors and methods of measurement.\n",
      "\n",
      "meg : bool | str\n",
      "    If True include MEG channels. If string it can be 'mag', 'grad',\n",
      "    'planar1' or 'planar2' to select only magnetometers, all\n",
      "    gradiometers, or a specific type of gradiometer.\n",
      "eeg : bool\n",
      "    If True include EEG channels.\n",
      "stim : bool\n",
      "    If True include stimulus channels.\n",
      "eog : bool\n",
      "    If True include EOG channels.\n",
      "ecg : bool\n",
      "    If True include ECG channels.\n",
      "emg : bool\n",
      "    If True include EMG channels.\n",
      "ref_meg : bool | str\n",
      "    If True include CTF / 4D reference channels. If 'auto', reference\n",
      "    channels are included if compensations are present and ``meg`` is\n",
      "    not False. Can also be the string options for the ``meg``\n",
      "    parameter.\n",
      "misc : bool\n",
      "    If True include miscellaneous analog channels.\n",
      "resp : bool\n",
      "    If ``True`` include respiratory channels.\n",
      "chpi : bool\n",
      "    If True include continuous HPI coil channels.\n",
      "exci : bool\n",
      "    Flux excitation channel used to be a stimulus channel.\n",
      "ias : bool\n",
      "    Internal Active Shielding data (maybe on Triux only).\n",
      "syst : bool\n",
      "    System status channel information (on Triux systems only).\n",
      "seeg : bool\n",
      "    Stereotactic EEG channels.\n",
      "dipole : bool\n",
      "    Dipole time course channels.\n",
      "gof : bool\n",
      "    Dipole goodness of fit channels.\n",
      "bio : bool\n",
      "    Bio channels.\n",
      "ecog : bool\n",
      "    Electrocorticography channels.\n",
      "fnirs : bool | str\n",
      "    Functional near-infrared spectroscopy channels. If True include all\n",
      "    fNIRS channels. If False (default) include none. If string it can\n",
      "    be 'hbo' (to include channels measuring oxyhemoglobin) or 'hbr' (to\n",
      "    include channels measuring deoxyhemoglobin).\n",
      "csd : bool\n",
      "    EEG-CSD channels.\n",
      "dbs : bool\n",
      "    Deep brain stimulation channels.\n",
      "temperature : bool\n",
      "    Temperature channels.\n",
      "gsr : bool\n",
      "    Galvanic skin response channels.\n",
      "include : list of str\n",
      "    List of additional channels to include. If empty do not include\n",
      "    any.\n",
      "exclude : list of str | str\n",
      "    List of channels to exclude. If 'bads' (default), exclude channels\n",
      "    in ``info['bads']``.\n",
      "selection : list of str\n",
      "    Restrict sensor channels (MEG, EEG, etc.) to this list of channel names.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "sel : array of int\n",
      "    Indices of good channels.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Documents/code_dev/mnepython/mne/io/pick.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "mne.pick_types?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the path to the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have downloaded the `ds000117-practical` folder. We have to let Python know, where to find this folder on your disk. You will have to adjust the path below to reflect your computer and path structure!\n",
    "You can print the whole path and check the directory to double check it's correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need this package for path management:\n",
    "import os\n",
    "\n",
    "# Change the following path to where the folder ds000117-practical is on your disk\n",
    "data_path = os.path.expanduser(\"~/Documents/teaching/practical_meeg_2022_data/ds000117\")\n",
    "\n",
    "raw_fname = os.path.join(data_path,\n",
    "    'derivatives/meg_derivatives/sub-01/ses-meg/meg/sub-01_ses-meg_task-facerecognition_run-01_proc-sss_meg.fif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brittawe/Documents/teaching/practical_meeg_2022_data/ds000117/derivatives/meg_derivatives/sub-01/ses-meg/meg/sub-01_ses-meg_task-facerecognition_run-01_proc-sss_meg.fif\n"
     ]
    }
   ],
   "source": [
    "print(raw_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m/Users/brittawe/Documents/teaching/practical_meeg_2022_data/ds000117/derivatives/meg_derivatives/sub-01/ses-meg/meg/sub-01_ses-meg_task-facerecognition_run-01_proc-sss_meg.fif\u001b[m\u001b[m@\n"
     ]
    }
   ],
   "source": [
    "ls $raw_fname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access and read the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mmne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_raw_fif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mallow_maxshield\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpreload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mon_split_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Reader function for Raw FIF data.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "fname : str | file-like\n",
      "    The raw filename to load. For files that have automatically been split,\n",
      "    the split part will be automatically loaded. Filenames should end\n",
      "    with raw.fif, raw.fif.gz, raw_sss.fif, raw_sss.fif.gz, raw_tsss.fif,\n",
      "    raw_tsss.fif.gz, or _meg.fif. If a file-like object is provided,\n",
      "    preloading must be used.\n",
      "\n",
      "    .. versionchanged:: 0.18\n",
      "       Support for file-like objects.\n",
      "allow_maxshield : bool | str (default False)\n",
      "    If True, allow loading of data that has been recorded with internal\n",
      "    active compensation (MaxShield). Data recorded with MaxShield should\n",
      "    generally not be loaded directly, but should first be processed using\n",
      "    SSS/tSSS to remove the compensation signals that may also affect brain\n",
      "    activity. Can also be \"yes\" to load without eliciting a warning.\n",
      "\n",
      "preload : bool or str (default False)\n",
      "    Preload data into memory for data manipulation and faster indexing.\n",
      "    If True, the data will be preloaded into memory (fast, requires\n",
      "    large amount of memory). If preload is a string, preload is the\n",
      "    file name of a memory-mapped file which is used to store the data\n",
      "    on the hard drive (slower, requires less memory).\n",
      "\n",
      "on_split_missing : str\n",
      "    Can be ``'raise'`` (default) to raise an error, ``'warn'`` to emit a\n",
      "    warning, or ``'ignore'`` to ignore when split file is missing.\n",
      "\n",
      "    .. versionadded:: 0.22\n",
      "\n",
      "verbose : bool | str | int | None\n",
      "    Control verbosity of the logging output. If ``None``, use the default\n",
      "    verbosity level. See the :ref:`logging documentation <tut-logging>` and\n",
      "    :func:`mne.verbose` for details. Should only be passed as a keyword\n",
      "    argument.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "raw : instance of Raw\n",
      "    A Raw object containing FIF data.\n",
      "\n",
      "Notes\n",
      "-----\n",
      ".. versionadded:: 0.9.0\n",
      "\n",
      "When reading a FIF file, note that the first N seconds annotated\n",
      "``BAD_ACQ_SKIP`` are **skipped**. They are removed from ``raw.times`` and\n",
      "``raw.n_times`` parameters but ``raw.first_samp`` and ``raw.first_time``\n",
      "are updated accordingly.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Documents/code_dev/mnepython/mne/io/fiff/raw.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "mne.io.read_raw_fif?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Raw | sub-01_ses-meg_task-facerecognition_run-01_proc-sss_meg.fif, 404 x 540100 (491.0 s), ~7.0 MB, data not loaded>\n"
     ]
    }
   ],
   "source": [
    "raw = mne.io.read_raw_fif(raw_fname, preload=False)\n",
    "print(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>March 22, 1941  11:04:14 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>MEG</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "            \n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>137 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>204 Gradiometers, 102 Magnetometers, 74 EEG, 3 Stimulus, 12 misc, 9 CHPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>1100.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>356.40 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>sub-01_ses-meg_task-facerecognition_run-01_proc-sss_meg.fif</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:08:11 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Raw | sub-01_ses-meg_task-facerecognition_run-01_proc-sss_meg.fif, 404 x 540100 (491.0 s), ~7.0 MB, data not loaded>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For general info on importing data you can check:\n",
    "- for MEG: https://mne.tools/stable/auto_tutorials/io/plot_10_reading_meg_data.html\n",
    "- for EEG: https://mne.tools/stable/auto_tutorials/io/plot_20_reading_eeg_data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand your data file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now let's look at the measurement info. It can give details about:\n",
    "\n",
    "   - sampling rate\n",
    "   - filtering parameters\n",
    "   - available channel types\n",
    "   - bad channels\n",
    "   - etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Info | 23 non-empty values\n",
      " acq_pars: ACQch001 110113 ACQch002 110112 ACQch003 110111 ACQch004 110122 ...\n",
      " bads: []\n",
      " ch_names: MEG0113, MEG0112, MEG0111, MEG0122, MEG0123, MEG0121, MEG0132, ...\n",
      " chs: 204 Gradiometers, 102 Magnetometers, 74 EEG, 3 Stimulus, 12 misc, 9 CHPI\n",
      " custom_ref_applied: False\n",
      " description: (meg) Vectorview system at Cambridge\n",
      " dev_head_t: MEG device -> head transform\n",
      " dig: 137 items (3 Cardinal, 5 HPI, 75 EEG, 54 Extra)\n",
      " events: 1 item (list)\n",
      " experimenter: MEG\n",
      " file_id: 4 items (dict)\n",
      " highpass: 0.0 Hz\n",
      " hpi_meas: 1 item (list)\n",
      " hpi_results: 1 item (list)\n",
      " hpi_subsystem: 2 items (dict)\n",
      " line_freq: 50.0\n",
      " lowpass: 356.4 Hz\n",
      " meas_date: 1941-03-22 11:04:14 UTC\n",
      " meas_id: 4 items (dict)\n",
      " nchan: 404\n",
      " proc_history: 1 item (list)\n",
      " proj_id: 1 item (ndarray)\n",
      " proj_name: dgw_studies\n",
      " projs: []\n",
      " sfreq: 1100.0 Hz\n",
      " subject_info: 2 items (dict)\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "print(raw.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Exercise</b>:\n",
    "     <ul>\n",
    "    <li>How many channels do you have for each type of sensors?</li>\n",
    "    <li>What is the sampling frequency?</li>\n",
    "    <li>Have the data been filtered?</li>\n",
    "    <li>What is the frequency of the line noise?</li>\n",
    "    <li>Is there any bad channel?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A closer look at the info dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "raw.info is just a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(raw.info, dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can access its elements this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1100.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.info['sfreq']  # Sampling frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.info['bads']  # list of marked bad channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.info['line_freq']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A closer look at the channels\n",
    "Next let's see what channels are present. It is available via the `raw.ch_names` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MEG0113',\n",
       " 'MEG0112',\n",
       " 'MEG0111',\n",
       " 'MEG0122',\n",
       " 'MEG0123',\n",
       " 'MEG0121',\n",
       " 'MEG0132',\n",
       " 'MEG0133',\n",
       " 'MEG0131',\n",
       " 'MEG0143']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.ch_names[:10]  # this prints the first ten channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can index it as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MEG0432'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.ch_names[42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also query the channel type of a specific channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel #75 is of type: grad\n",
      "Channel #320 is of type: eeg\n"
     ]
    }
   ],
   "source": [
    "channel_type = mne.io.pick.channel_type(raw.info, 75)\n",
    "print('Channel #75 is of type:', channel_type)  # print this out in a neat way\n",
    "\n",
    "channel_type = mne.io.pick.channel_type(raw.info, 320)\n",
    "print('Channel #320 is of type:', channel_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The info also contains all the details about the sensors (type, locations, coordinate frame etc.) in `chs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw.info['chs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw.info['chs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scanno': 1,\n",
       " 'logno': 113,\n",
       " 'kind': 1 (FIFFV_MEG_CH),\n",
       " 'range': 1.9073486328125e-05,\n",
       " 'cal': 3.250000046861601e-09,\n",
       " 'coil_type': 3012 (FIFFV_COIL_VV_PLANAR_T1),\n",
       " 'loc': array([-0.1066    ,  0.0464    , -0.0604    , -0.01532829,  0.00619847,\n",
       "        -0.99986327, -0.18597366, -0.98255992, -0.00331254, -0.98243302,\n",
       "         0.185894  ,  0.016216  ]),\n",
       " 'unit': 201 (FIFF_UNIT_T_M),\n",
       " 'unit_mul': 0 (FIFF_UNITM_NONE),\n",
       " 'ch_name': 'MEG0113',\n",
       " 'coord_frame': 1 (FIFFV_COORD_DEVICE)}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.info['chs'][0]  # check the first channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scanno': 331,\n",
       " 'logno': 25,\n",
       " 'kind': 2 (FIFFV_EEG_CH),\n",
       " 'range': 0.00030517578125,\n",
       " 'cal': 0.00019999999494757503,\n",
       " 'coil_type': 1 (FIFFV_COIL_EEG),\n",
       " 'loc': array([ 5.63842431e-02,  3.68367434e-02,  9.40217227e-02,  8.26010015e-04,\n",
       "         1.14762366e-01, -2.10680366e-02,  0.00000000e+00,  1.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00]),\n",
       " 'unit': 107 (FIFF_UNIT_V),\n",
       " 'unit_mul': 0 (FIFF_UNITM_NONE),\n",
       " 'ch_name': 'EEG025',\n",
       " 'coord_frame': 4 (FIFFV_COORD_HEAD)}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.info['chs'][330]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know that there is EEG and MEG channels in the data, we can plot both separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5t/zzrvvsdd03721w2g_3y4w8xh0000gn/T/ipykernel_6486/2013439534.py:1: RuntimeWarning: (X, Y) fit (3.1, 32.2) more than 20 mm from head frame origin\n",
      "  raw.plot_sensors(kind='topomap', ch_type='grad');\n"
     ]
    }
   ],
   "source": [
    "raw.plot_sensors(kind='topomap', ch_type='grad');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5t/zzrvvsdd03721w2g_3y4w8xh0000gn/T/ipykernel_6486/265059241.py:1: RuntimeWarning: (X, Y) fit (3.1, 32.2) more than 20 mm from head frame origin\n",
      "  raw.plot_sensors(kind='topomap', ch_type='eeg');\n"
     ]
    }
   ],
   "source": [
    "raw.plot_sensors(kind='topomap', ch_type='eeg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting channel types\n",
    "\n",
    "Some channels are wrongly defined as EEG in the file. \n",
    "Two of these are EOG (EEG061 and EEG062) and EEG063 is actually an ECG channel. EEG064 was recording but not connected to anything, so we'll make it `'misc'` instead. \n",
    "We will now set the channel types for those wrongly classified channels. This will be useful for automatic artifact rejection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_channel_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Define the sensor type of channels.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "mapping : dict\n",
      "    A dictionary mapping a channel to a sensor type (str), e.g.,\n",
      "    ``{'EEG061': 'eog'}``.\n",
      "\n",
      "verbose : bool | str | int | None\n",
      "    Control verbosity of the logging output. If ``None``, use the default\n",
      "    verbosity level. See the :ref:`logging documentation <tut-logging>` and\n",
      "    :func:`mne.verbose` for details. Should only be passed as a keyword\n",
      "    argument.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "inst : instance of Raw | Epochs | Evoked\n",
      "    The instance (modified in place).\n",
      "\n",
      "    .. versionchanged:: 0.20\n",
      "       Return the instance.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The following sensor types are accepted:\n",
      "\n",
      "    ecg, eeg, emg, eog, exci, ias, misc, resp, seeg, dbs, stim, syst,\n",
      "    ecog, hbo, hbr, fnirs_cw_amplitude, fnirs_fd_ac_amplitude,\n",
      "    fnirs_fd_phase, fnirs_od, temperature, gsr\n",
      "\n",
      ".. versionadded:: 0.9.0\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Documents/code_dev/mnepython/mne/channels/channels.py\n",
      "\u001b[0;31mType:\u001b[0m      method\n"
     ]
    }
   ],
   "source": [
    "raw.set_channel_types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>March 22, 1941  11:04:14 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>MEG</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "            \n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>137 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>204 Gradiometers, 102 Magnetometers, 70 EEG, 2 EOG, 1 ECG, 1 misc, 1 Stimulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>EOG061, EOG062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>ECG063</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>300.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>40.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>sub-01_ses-meg_task-facerecognition_run-01_proc-sss_meg.fif</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:08:11 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Raw | sub-01_ses-meg_task-facerecognition_run-01_proc-sss_meg.fif, 381 x 147300 (491.0 s), ~435.2 MB, data loaded>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.set_channel_types({'EEG061': 'eog',  # actually EOG not EEG\n",
    "                       'EEG062': 'eog',  # actually EOG not EEG\n",
    "                       'EEG063': 'ecg',  # actually ECG not EEG\n",
    "                       'EEG064': 'misc'})  # EEG064 free-floating electrode\n",
    "\n",
    "# we also rename the EOG and ECG channels:\n",
    "raw.rename_channels({'EEG061': 'EOG061',\n",
    "                     'EEG062': 'EOG062',\n",
    "                     'EEG063': 'ECG063'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>March 22, 1941  11:04:14 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>MEG</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "            \n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>137 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>204 Gradiometers, 102 Magnetometers, 70 EEG, 2 EOG, 1 ECG, 13 misc, 3 Stimulus, 9 CHPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>EOG061, EOG062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>ECG063</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>1100.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>356.40 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "</table>"
      ],
      "text/plain": [
       "<Info | 23 non-empty values\n",
       " acq_pars: ACQch001 110113 ACQch002 110112 ACQch003 110111 ACQch004 110122 ...\n",
       " bads: []\n",
       " ch_names: MEG0113, MEG0112, MEG0111, MEG0122, MEG0123, MEG0121, MEG0132, ...\n",
       " chs: 204 Gradiometers, 102 Magnetometers, 70 EEG, 2 EOG, 1 ECG, 13 misc, 3 Stimulus, 9 CHPI\n",
       " custom_ref_applied: False\n",
       " description: (meg) Vectorview system at Cambridge\n",
       " dev_head_t: MEG device -> head transform\n",
       " dig: 137 items (3 Cardinal, 5 HPI, 75 EEG, 54 Extra)\n",
       " events: 1 item (list)\n",
       " experimenter: MEG\n",
       " file_id: 4 items (dict)\n",
       " highpass: 0.0 Hz\n",
       " hpi_meas: 1 item (list)\n",
       " hpi_results: 1 item (list)\n",
       " hpi_subsystem: 2 items (dict)\n",
       " line_freq: 50.0\n",
       " lowpass: 356.4 Hz\n",
       " meas_date: 1941-03-22 11:04:14 UTC\n",
       " meas_id: 4 items (dict)\n",
       " nchan: 404\n",
       " proc_history: 1 item (list)\n",
       " proj_id: 1 item (ndarray)\n",
       " proj_name: dgw_studies\n",
       " projs: []\n",
       " sfreq: 1100.0 Hz\n",
       " subject_info: 2 items (dict)\n",
       ">"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5t/zzrvvsdd03721w2g_3y4w8xh0000gn/T/ipykernel_6486/265059241.py:1: RuntimeWarning: (X, Y) fit (3.1, 32.2) more than 20 mm from head frame origin\n",
      "  raw.plot_sensors(kind='topomap', ch_type='eeg');\n"
     ]
    }
   ],
   "source": [
    "raw.plot_sensors(kind='topomap', ch_type='eeg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the data\n",
    "\n",
    "To access the data just use the `[]` syntax as to access any element of a list, dict etc. Note that `raw[]` returns two things: the data and the times array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "start, stop = 0, 10\n",
    "data, times = raw[:, start:stop]  # fetch all channels and the first 10 time points\n",
    "print(data.shape)\n",
    "print(times.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.00090909, 0.00181818, 0.00272727, 0.00363636,\n",
       "       0.00454545, 0.00545455, 0.00636364, 0.00727273, 0.00818182])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times  # always starts at 0 by convention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `raw[]` returns both the data and the times array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling the data\n",
    "\n",
    "We will now change the sampling frequency of the data to speed up the computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>March 22, 1941  11:04:14 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>MEG</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "            \n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>137 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>204 Gradiometers, 102 Magnetometers, 74 EEG, 3 Stimulus, 12 misc, 9 CHPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>300.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>150.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>sub-01_ses-meg_task-facerecognition_run-01_proc-sss_meg.fif</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:08:11 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Raw | sub-01_ses-meg_task-facerecognition_run-01_proc-sss_meg.fif, 404 x 147300 (491.0 s), ~461.0 MB, data loaded>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.load_data()  # load data into memory\n",
    "raw.resample(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's remove unecessary channels - some empty stimulus channels, misc. channels, and HPI channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_channels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Drop channel(s).\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "ch_names : iterable or str\n",
      "    Iterable (e.g. list) of channel name(s) or channel name to remove.\n",
      "\n",
      "on_missing : 'raise' | 'warn' | 'ignore'\n",
      "    Can be ``'raise'`` (default) to raise an error, ``'warn'`` to emit a\n",
      "    warning, or ``'ignore'`` to ignore when entries in ch_names are not present in the raw instance.\n",
      "\n",
      "    .. versionadded:: 0.23.0\n",
      "\n",
      "Returns\n",
      "-------\n",
      "inst : instance of Raw, Epochs, or Evoked\n",
      "    The modified instance.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "reorder_channels\n",
      "pick_channels\n",
      "pick_types\n",
      "\n",
      "Notes\n",
      "-----\n",
      ".. versionadded:: 0.9.0\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Documents/code_dev/mnepython/mne/channels/channels.py\n",
      "\u001b[0;31mType:\u001b[0m      method\n"
     ]
    }
   ],
   "source": [
    "raw.drop_channels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['STI201', 'STI301', 'MISC201', 'MISC202', 'MISC203',\n",
    "           'MISC204', 'MISC205', 'MISC206', 'MISC301', 'MISC302',\n",
    "           'MISC303', 'MISC304', 'MISC305', 'MISC306', 'CHPI001',\n",
    "           'CHPI002', 'CHPI003', 'CHPI004', 'CHPI005', 'CHPI006',\n",
    "           'CHPI007', 'CHPI008', 'CHPI009']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>March 22, 1941  11:04:14 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>MEG</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "            \n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>137 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>204 Gradiometers, 102 Magnetometers, 74 EEG, 1 Stimulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>300.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>150.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>sub-01_ses-meg_task-facerecognition_run-01_proc-sss_meg.fif</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:08:11 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Raw | sub-01_ses-meg_task-facerecognition_run-01_proc-sss_meg.fif, 381 x 147300 (491.0 s), ~435.2 MB, data loaded>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.drop_channels(to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering the data and plotting raw data\n",
    "\n",
    "We want to filter the data betwenn 0 and 40 Hz using a linear-phase finite-impulse response (FIR) filter.\n",
    "**Exercise**: which parameters do we have to set to achieve this, based on the docstring?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0ml_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mh_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpicks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfilter_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0ml_trans_bandwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mh_trans_bandwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fir'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0miir_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mphase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'zero'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfir_window\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hamming'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfir_design\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'firwin'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mskip_by_annotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'edge'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bad_acq_skip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'reflect_limited'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Filter a subset of channels.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "\n",
      "l_freq : float | None\n",
      "    For FIR filters, the lower pass-band edge; for IIR filters, the lower\n",
      "    cutoff frequency. If None the data are only low-passed.\n",
      "\n",
      "h_freq : float | None\n",
      "    For FIR filters, the upper pass-band edge; for IIR filters, the upper\n",
      "    cutoff frequency. If None the data are only high-passed.\n",
      "picks : str | array-like | slice | None\n",
      "    Channels to include. Slices and lists of integers will be interpreted as \n",
      "    channel indices. In lists, channel *type* strings (e.g., ``['meg', \n",
      "    'eeg']``) will pick channels of those types, channel *name* strings (e.g., \n",
      "    ``['MEG0111', 'MEG2623']`` will pick the given channels. Can also be the \n",
      "    string values \"all\" to pick all channels, or \"data\" to pick :term:`data \n",
      "    channels`. None (default) will pick all data channels. Note that channels \n",
      "    in ``info['bads']`` *will be included* if their names or indices are \n",
      "    explicitly provided.\n",
      "\n",
      "filter_length : str | int\n",
      "    Length of the FIR filter to use (if applicable):\n",
      "\n",
      "    * **'auto' (default)**: The filter length is chosen based\n",
      "      on the size of the transition regions (6.6 times the reciprocal\n",
      "      of the shortest transition band for fir_window='hamming'\n",
      "      and fir_design=\"firwin2\", and half that for \"firwin\").\n",
      "    * **str**: A human-readable time in\n",
      "      units of \"s\" or \"ms\" (e.g., \"10s\" or \"5500ms\") will be\n",
      "      converted to that number of samples if ``phase=\"zero\"``, or\n",
      "      the shortest power-of-two length at least that duration for\n",
      "      ``phase=\"zero-double\"``.\n",
      "    * **int**: Specified length in samples. For fir_design=\"firwin\",\n",
      "      this should not be used.\n",
      "\n",
      "l_trans_bandwidth : float | str\n",
      "    Width of the transition band at the low cut-off frequency in Hz\n",
      "    (high pass or cutoff 1 in bandpass). Can be \"auto\"\n",
      "    (default) to use a multiple of ``l_freq``::\n",
      "\n",
      "        min(max(l_freq * 0.25, 2), l_freq)\n",
      "\n",
      "    Only used for ``method='fir'``.\n",
      "\n",
      "h_trans_bandwidth : float | str\n",
      "    Width of the transition band at the high cut-off frequency in Hz\n",
      "    (low pass or cutoff 2 in bandpass). Can be \"auto\"\n",
      "    (default in 0.14) to use a multiple of ``h_freq``::\n",
      "\n",
      "        min(max(h_freq * 0.25, 2.), info['sfreq'] / 2. - h_freq)\n",
      "\n",
      "    Only used for ``method='fir'``.\n",
      "\n",
      "n_jobs : int | str\n",
      "    Number of jobs to run in parallel. Can be 'cuda' if ``cupy``\n",
      "    is installed properly and method='fir'.\n",
      "\n",
      "method : str\n",
      "    'fir' will use overlap-add FIR filtering, 'iir' will use IIR\n",
      "    forward-backward filtering (via filtfilt).\n",
      "\n",
      "iir_params : dict | None\n",
      "    Dictionary of parameters to use for IIR filtering.\n",
      "    If iir_params is None and method=\"iir\", 4th order Butterworth will be used.\n",
      "    For more information, see :func:`mne.filter.construct_iir_filter`.\n",
      "\n",
      "phase : str\n",
      "    Phase of the filter, only used if ``method='fir'``.\n",
      "    Symmetric linear-phase FIR filters are constructed, and if ``phase='zero'``\n",
      "    (default), the delay of this filter is compensated for, making it\n",
      "    non-causal. If ``phase='zero-double'``,\n",
      "    then this filter is applied twice, once forward, and once backward\n",
      "    (also making it non-causal). If ``'minimum'``, then a minimum-phase filter\n",
      "    will be constricted and applied, which is causal but has weaker stop-band\n",
      "    suppression.\n",
      "\n",
      "    .. versionadded:: 0.13\n",
      "\n",
      "fir_window : str\n",
      "    The window to use in FIR design, can be \"hamming\" (default),\n",
      "    \"hann\" (default in 0.13), or \"blackman\".\n",
      "\n",
      "    .. versionadded:: 0.15\n",
      "\n",
      "fir_design : str\n",
      "    Can be \"firwin\" (default) to use :func:`scipy.signal.firwin`,\n",
      "    or \"firwin2\" to use :func:`scipy.signal.firwin2`. \"firwin\" uses\n",
      "    a time-domain design technique that generally gives improved\n",
      "    attenuation using fewer samples than \"firwin2\".\n",
      "\n",
      "    .. versionadded:: 0.15\n",
      "skip_by_annotation : str | list of str\n",
      "    If a string (or list of str), any annotation segment that begins\n",
      "    with the given string will not be included in filtering, and\n",
      "    segments on either side of the given excluded annotated segment\n",
      "    will be filtered separately (i.e., as independent signals).\n",
      "    The default (``('edge', 'bad_acq_skip')`` will separately filter\n",
      "    any segments that were concatenated by :func:`mne.concatenate_raws`\n",
      "    or :meth:`mne.io.Raw.append`, or separated during acquisition.\n",
      "    To disable, provide an empty list. Only used if ``inst`` is raw.\n",
      "\n",
      "    .. versionadded:: 0.16.\n",
      "\n",
      "pad : str\n",
      "    The type of padding to use. Supports all :func:`numpy.pad` ``mode``\n",
      "    options. Can also be ``\"reflect_limited\"``, which pads with a\n",
      "    reflected version of each vector mirrored on the first and last values\n",
      "    of the vector, followed by zeros.\n",
      "\n",
      "    Only used for ``method='fir'``.\n",
      "\n",
      "verbose : bool | str | int | None\n",
      "    Control verbosity of the logging output. If ``None``, use the default\n",
      "    verbosity level. See the :ref:`logging documentation <tut-logging>` and\n",
      "    :func:`mne.verbose` for details. Should only be passed as a keyword\n",
      "    argument.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "inst : instance of Epochs, Evoked, or Raw\n",
      "    The filtered data.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "mne.filter.create_filter\n",
      "mne.Evoked.savgol_filter\n",
      "mne.io.Raw.notch_filter\n",
      "mne.io.Raw.resample\n",
      "mne.filter.create_filter\n",
      "mne.filter.filter_data\n",
      "mne.filter.construct_iir_filter\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Applies a zero-phase low-pass, high-pass, band-pass, or band-stop\n",
      "filter to the channels selected by ``picks``.\n",
      "The data are modified inplace.\n",
      "\n",
      "The object has to have the data loaded e.g. with ``preload=True``\n",
      "or ``self.load_data()``.\n",
      "\n",
      "``l_freq`` and ``h_freq`` are the frequencies below which and above\n",
      "which, respectively, to filter out of the data. Thus the uses are:\n",
      "\n",
      "    * ``l_freq < h_freq``: band-pass filter\n",
      "    * ``l_freq > h_freq``: band-stop filter\n",
      "    * ``l_freq is not None and h_freq is None``: high-pass filter\n",
      "    * ``l_freq is None and h_freq is not None``: low-pass filter\n",
      "\n",
      "``self.info['lowpass']`` and ``self.info['highpass']`` are only\n",
      "updated with picks=None.\n",
      "\n",
      ".. note:: If n_jobs > 1, more memory is required as\n",
      "          ``len(picks) * n_times`` additional time points need to\n",
      "          be temporarily stored in memory.\n",
      "\n",
      "For more information, see the tutorials\n",
      ":ref:`disc-filtering` and :ref:`tut-filter-resample` and\n",
      ":func:`mne.filter.create_filter`.\n",
      "\n",
      ".. versionadded:: 0.15\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Documents/code_dev/mnepython/mne/io/base.py\n",
      "\u001b[0;31mType:\u001b[0m      method\n"
     ]
    }
   ],
   "source": [
    "raw.filter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what effect filtering has for our data, let's quickly look at our data first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mne_qt_browser._pg_figure.MNEQtBrowser at 0x15cae71c0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>March 22, 1941  11:04:14 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>MEG</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "            \n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>137 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>204 Gradiometers, 102 Magnetometers, 74 EEG, 1 Stimulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>300.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>40.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>sub-01_ses-meg_task-facerecognition_run-01_proc-sss_meg.fif</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:08:11 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Raw | sub-01_ses-meg_task-facerecognition_run-01_proc-sss_meg.fif, 381 x 147300 (491.0 s), ~435.2 MB, data loaded>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.filter(0, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we filtered our data, let's look at it again. Can you spot the difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mne_qt_browser._pg_figure.MNEQtBrowser at 0x1692f2a70>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:**\n",
    "\n",
    "- Which data changed more due to the filtering: EEG or MEG?\n",
    "- Can you find reasons why?\n",
    "- Do you see any bad channels?\n",
    "- Is there any characteristics you can see in the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on visualizing of raw data, see here: \n",
    "https://mne.tools/0.16/auto_tutorials/plot_visualize_raw.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5t/zzrvvsdd03721w2g_3y4w8xh0000gn/T/ipykernel_6486/1245969198.py\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# d = raw.get_data(picks=('eeg', 'mag'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpicks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'grad'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# d = raw.get_data(picks=['EEG001', 'EEG002'])\n",
    "# d = raw.get_data(picks=('eeg', 'mag'))\n",
    "d = raw.get_data(picks=('grad',))\n",
    "np.max(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 15000)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### TODO\n",
    "start = 0\n",
    "stop = int(50 * raw.info['sfreq'])\n",
    "data = raw.get_data('STI101', start=start, stop=stop)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.times[start:stop].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xa569bd950>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(raw.times[start:stop], data.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the event structure of the data\n",
    "\n",
    "The data has different events, which mark which stimulus was shown to the participants. The event/trigger structure is as follows:\n",
    "- 5, 6, 7: famous faces\n",
    "- 13, 14, 15: unfamiliar faces\n",
    "- 17, 18, 19: scrambled faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first look at which events are there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259 events found\n",
      "Event IDs: [   5    6    7   13   14   15   17   18   19  256  261  262  263  269\n",
      "  270  271  273  274  275 4096 4101 4102 4103 4109 4110 4111 4113 4114\n",
      " 4115 4352]\n"
     ]
    }
   ],
   "source": [
    "events = mne.find_events(raw, stim_channel='STI101', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:**\n",
    "Let's inspect the `events` object a bit more:\n",
    "- What is the type of the variable events?\n",
    "- What is the meaning of the 3 columns of events?\n",
    "- How many events of type 5 do you see?\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(events[:, 2] == 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was a time offset of 34.5 ms in the stimulus presentation. We need to correct the events accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay = int(round(0.0345 * raw.info['sfreq']))\n",
    "events[:, 0] = events[:, 0] + delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the paradigm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = events[events[:, 2] < 20] # take only events with code less than 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = mne.viz.plot_events(events, raw.info['sfreq']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For event trigger and conditions we use a Python dictionary with keys that contain \"/\" for grouping sub-conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_id = {\n",
    "    'face/famous/first': 5,\n",
    "    'face/famous/immediate': 6,\n",
    "    'face/famous/long': 7,\n",
    "    'face/unfamiliar/first': 13,\n",
    "    'face/unfamiliar/immediate': 14,\n",
    "    'face/unfamiliar/long': 15,\n",
    "    'scrambled/first': 17,\n",
    "    'scrambled/immediate': 18,\n",
    "    'scrambled/long': 19,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = mne.viz.plot_events(events, sfreq=raw.info['sfreq'],\n",
    "                          event_id=event_id);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now re-visit our raw data plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot(event_id=event_id, events=events);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epoch data and artifact rejection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define epochs parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin = -0.5  # start of each epoch (500ms before the trigger)\n",
    "tmax = 2.0  # end of each epoch (2000ms after the trigger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the baseline period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = (-0.2, 0)  # means from 200ms before to stim onset (t = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest (and maybe also most dangerous?) way to clean your data is to define peak-to-peak (amplitude range) rejection parameters for gradiometers, magnetometers and EOG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "reject = dict(grad=4000e-13, mag=4e-12, eog=150e-6)  # this can be highly data dependent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>REMARK</b>:\n",
    "     <ul>\n",
    "    <li>The <a href=\"https://autoreject.github.io/\">autoreject</a> project aims to solve this problem of reject parameter setting. See the <a href=\"https://www.sciencedirect.com/science/article/pii/S1053811917305013\">paper</a>.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also pick channels now - MEG, EEG and EOG channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "picks = mne.pick_types(raw.info, meg=True, eeg=True, eog=True,\n",
    "                       stim=False, exclude='bads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can put all of this together and created epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = mne.Epochs(raw, events, event_id, tmin, tmax, proj=True,\n",
    "                    picks=picks, baseline=baseline,\n",
    "                    reject=reject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Epochs |  146 events (good & bad), -0.5 - 2 sec, baseline -0.2  0 sec, ~7.0 MB, data not loaded,\n",
      " 'face/famous/first': 25\n",
      " 'face/famous/immediate': 10\n",
      " 'face/famous/long': 14\n",
      " 'face/unfamiliar/first': 25\n",
      " 'face/unfamiliar/immediate': 12\n",
      " 'face/unfamiliar/long': 10\n",
      " 'scrambled/first': 25\n",
      " 'scrambled/immediate': 14\n",
      " 'scrambled/long': 11>\n"
     ]
    }
   ],
   "source": [
    "print(epochs)  # let's look at some details about the epochs object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        \n",
       "        <td>face/famous/first: 13<br/>face/famous/immediate: 3<br/>face/famous/long: 6<br/>face/unfamiliar/first: 17<br/>face/unfamiliar/immediate: 4<br/>face/unfamiliar/long: 6<br/>scrambled/first: 15<br/>scrambled/immediate: 9<br/>scrambled/long: 6</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>-0.500  2.000 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>-0.200  0.000 sec</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Epochs |  79 events (all good), -0.5 - 2 sec, baseline -0.2  0 sec, ~7.0 MB, data not loaded,\n",
       " 'face/famous/first': 13\n",
       " 'face/famous/immediate': 3\n",
       " 'face/famous/long': 6\n",
       " 'face/unfamiliar/first': 17\n",
       " 'face/unfamiliar/immediate': 4\n",
       " 'face/unfamiliar/long': 6\n",
       " 'scrambled/first': 15\n",
       " 'scrambled/immediate': 9\n",
       " 'scrambled/long': 6>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs.drop_bad()  # remove bad epochs based on reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        \n",
       "        <td>face/famous/first: 13<br/>face/famous/immediate: 3<br/>face/famous/long: 6<br/>face/unfamiliar/first: 17<br/>face/unfamiliar/immediate: 4<br/>face/unfamiliar/long: 6<br/>scrambled/first: 15<br/>scrambled/immediate: 9<br/>scrambled/long: 6</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>-0.500  2.000 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>-0.200  0.000 sec</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Epochs |  79 events (all good), -0.5 - 2 sec, baseline -0.2  0 sec, ~179.0 MB, data loaded,\n",
       " 'face/famous/first': 13\n",
       " 'face/famous/immediate': 3\n",
       " 'face/famous/long': 6\n",
       " 'face/unfamiliar/first': 17\n",
       " 'face/unfamiliar/immediate': 4\n",
       " 'face/unfamiliar/long': 6\n",
       " 'scrambled/first': 15\n",
       " 'scrambled/immediate': 9\n",
       " 'scrambled/long': 6>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs.load_data()  # load data in memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A closer look at artifact rejection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's have a closer look at the methods of the epochs object.\n",
    "Uncomment the line below and hit ``epochs.<TAB>``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how epochs were dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.plot_drop_log();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "('EOG062',)\n",
      "('EOG062',)\n",
      "()\n",
      "('EOG062',)\n",
      "()\n",
      "()\n",
      "('EOG062',)\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "for drop_log in epochs.drop_log[:20]:\n",
    "    print(drop_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare our `events` list to the events in `epochs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 3)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79, 3)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs.events.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait a second, did we just loose half of our epochs due to EOG???\n",
    "\n",
    "We can probably do better. Let's use the PCA-based signal space projection (SSP) to regress out spatial patterns related to EOG and other offenders, ie., ECG.\n",
    "\n",
    "Here is the workflow, we'll first detect EOG artifacts and visualize their impact. Then we'll compute related spatial patterns to mitigate these artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5t/zzrvvsdd03721w2g_3y4w8xh0000gn/T/ipykernel_6486/2897332736.py:3: RuntimeWarning: (X, Y) fit (3.1, 32.2) more than 20 mm from head frame origin\n",
      "  eog_epochs.average().plot_joint();\n",
      "/var/folders/5t/zzrvvsdd03721w2g_3y4w8xh0000gn/T/ipykernel_6486/2897332736.py:3: RuntimeWarning: (X, Y) fit (3.1, 32.2) more than 20 mm from head frame origin\n",
      "  eog_epochs.average().plot_joint();\n",
      "/var/folders/5t/zzrvvsdd03721w2g_3y4w8xh0000gn/T/ipykernel_6486/2897332736.py:3: RuntimeWarning: (X, Y) fit (3.1, 32.2) more than 20 mm from head frame origin\n",
      "  eog_epochs.average().plot_joint();\n",
      "/var/folders/5t/zzrvvsdd03721w2g_3y4w8xh0000gn/T/ipykernel_6486/2897332736.py:3: RuntimeWarning: (X, Y) fit (3.1, 32.2) more than 20 mm from head frame origin\n",
      "  eog_epochs.average().plot_joint();\n",
      "/var/folders/5t/zzrvvsdd03721w2g_3y4w8xh0000gn/T/ipykernel_6486/2897332736.py:3: RuntimeWarning: (X, Y) fit (3.1, 32.2) more than 20 mm from head frame origin\n",
      "  eog_epochs.average().plot_joint();\n",
      "/var/folders/5t/zzrvvsdd03721w2g_3y4w8xh0000gn/T/ipykernel_6486/2897332736.py:3: RuntimeWarning: (X, Y) fit (3.1, 32.2) more than 20 mm from head frame origin\n",
      "  eog_epochs.average().plot_joint();\n",
      "/var/folders/5t/zzrvvsdd03721w2g_3y4w8xh0000gn/T/ipykernel_6486/2897332736.py:3: RuntimeWarning: (X, Y) fit (3.1, 32.2) more than 20 mm from head frame origin\n",
      "  eog_epochs.average().plot_joint();\n"
     ]
    }
   ],
   "source": [
    "# There is a funciton to create EOG epochs;\n",
    "eog_epochs = mne.preprocessing.create_eog_epochs(raw.copy().filter(1, None))\n",
    "eog_epochs.average().plot_joint();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see where those EOG segments show up in our raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot(events=eog_epochs.events);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "projs_eog, _ = mne.preprocessing.compute_proj_eog(\n",
    "    raw, n_mag=3, n_grad=3, n_eeg=3, average=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Projection | EOG-planar--0.200-0.200-PCA-01, active : False, n_channels : 204, exp. var : 95.55%>,\n",
       " <Projection | EOG-planar--0.200-0.200-PCA-02, active : False, n_channels : 204, exp. var : 1.89%>,\n",
       " <Projection | EOG-planar--0.200-0.200-PCA-03, active : False, n_channels : 204, exp. var : 0.69%>,\n",
       " <Projection | EOG-axial--0.200-0.200-PCA-01, active : False, n_channels : 102, exp. var : 97.35%>,\n",
       " <Projection | EOG-axial--0.200-0.200-PCA-02, active : False, n_channels : 102, exp. var : 1.30%>,\n",
       " <Projection | EOG-axial--0.200-0.200-PCA-03, active : False, n_channels : 102, exp. var : 0.44%>,\n",
       " <Projection | EOG-eeg--0.200-0.200-PCA-01, active : False, n_channels : 70, exp. var : 99.14%>,\n",
       " <Projection | EOG-eeg--0.200-0.200-PCA-02, active : False, n_channels : 70, exp. var : 0.69%>,\n",
       " <Projection | EOG-eeg--0.200-0.200-PCA-03, active : False, n_channels : 70, exp. var : 0.11%>]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projs_eog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5t/zzrvvsdd03721w2g_3y4w8xh0000gn/T/ipykernel_6486/2024940583.py:1: RuntimeWarning: (X, Y) fit (3.1, 32.2) more than 20 mm from head frame origin\n",
      "  mne.viz.plot_projs_topomap(projs_eog, info=epochs.info);\n",
      "/var/folders/5t/zzrvvsdd03721w2g_3y4w8xh0000gn/T/ipykernel_6486/2024940583.py:1: RuntimeWarning: (X, Y) fit (3.1, 32.2) more than 20 mm from head frame origin\n",
      "  mne.viz.plot_projs_topomap(projs_eog, info=epochs.info);\n",
      "/var/folders/5t/zzrvvsdd03721w2g_3y4w8xh0000gn/T/ipykernel_6486/2024940583.py:1: RuntimeWarning: (X, Y) fit (3.1, 32.2) more than 20 mm from head frame origin\n",
      "  mne.viz.plot_projs_topomap(projs_eog, info=epochs.info);\n",
      "/var/folders/5t/zzrvvsdd03721w2g_3y4w8xh0000gn/T/ipykernel_6486/2024940583.py:1: RuntimeWarning: (X, Y) fit (3.1, 32.2) more than 20 mm from head frame origin\n",
      "  mne.viz.plot_projs_topomap(projs_eog, info=epochs.info);\n"
     ]
    }
   ],
   "source": [
    "mne.viz.plot_projs_topomap(projs_eog, info=epochs.info);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the important question is how many components one should keep? Tip: some of them don't look like clear artifact patterns. \n",
    "\n",
    "The good news is that we don't need to decide __*right*__ now.\n",
    "\n",
    "BUT: let's repeat this procedure for the ECG, i.e. heart beat artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5t/zzrvvsdd03721w2g_3y4w8xh0000gn/T/ipykernel_6486/434745471.py:3: RuntimeWarning: (X, Y) fit (3.1, 32.2) more than 20 mm from head frame origin\n",
      "  ecg_epochs.average().plot_joint()\n",
      "/var/folders/5t/zzrvvsdd03721w2g_3y4w8xh0000gn/T/ipykernel_6486/434745471.py:3: RuntimeWarning: (X, Y) fit (3.1, 32.2) more than 20 mm from head frame origin\n",
      "  ecg_epochs.average().plot_joint()\n",
      "/var/folders/5t/zzrvvsdd03721w2g_3y4w8xh0000gn/T/ipykernel_6486/434745471.py:3: RuntimeWarning: (X, Y) fit (3.1, 32.2) more than 20 mm from head frame origin\n",
      "  ecg_epochs.average().plot_joint()\n",
      "/var/folders/5t/zzrvvsdd03721w2g_3y4w8xh0000gn/T/ipykernel_6486/434745471.py:3: RuntimeWarning: (X, Y) fit (3.1, 32.2) more than 20 mm from head frame origin\n",
      "  ecg_epochs.average().plot_joint()\n",
      "/var/folders/5t/zzrvvsdd03721w2g_3y4w8xh0000gn/T/ipykernel_6486/434745471.py:3: RuntimeWarning: (X, Y) fit (3.1, 32.2) more than 20 mm from head frame origin\n",
      "  ecg_epochs.average().plot_joint()\n",
      "/var/folders/5t/zzrvvsdd03721w2g_3y4w8xh0000gn/T/ipykernel_6486/434745471.py:3: RuntimeWarning: (X, Y) fit (3.1, 32.2) more than 20 mm from head frame origin\n",
      "  ecg_epochs.average().plot_joint()\n",
      "/var/folders/5t/zzrvvsdd03721w2g_3y4w8xh0000gn/T/ipykernel_6486/434745471.py:3: RuntimeWarning: (X, Y) fit (3.1, 32.2) more than 20 mm from head frame origin\n",
      "  ecg_epochs.average().plot_joint()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Figure size 800x420 with 7 Axes>,\n",
       " <Figure size 800x420 with 7 Axes>,\n",
       " <Figure size 800x420 with 7 Axes>]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same business, same issue for ECG\n",
    "ecg_epochs = mne.preprocessing.create_ecg_epochs(raw.copy().filter(1, None))\n",
    "ecg_epochs.average().plot_joint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also face important insults from the cardiac signal... we'll project that out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5t/zzrvvsdd03721w2g_3y4w8xh0000gn/T/ipykernel_6486/178739447.py:3: RuntimeWarning: (X, Y) fit (3.1, 32.2) more than 20 mm from head frame origin\n",
      "  mne.viz.plot_projs_topomap(projs_ecg, info=epochs.info);\n",
      "/var/folders/5t/zzrvvsdd03721w2g_3y4w8xh0000gn/T/ipykernel_6486/178739447.py:3: RuntimeWarning: (X, Y) fit (3.1, 32.2) more than 20 mm from head frame origin\n",
      "  mne.viz.plot_projs_topomap(projs_ecg, info=epochs.info);\n",
      "/var/folders/5t/zzrvvsdd03721w2g_3y4w8xh0000gn/T/ipykernel_6486/178739447.py:3: RuntimeWarning: (X, Y) fit (3.1, 32.2) more than 20 mm from head frame origin\n",
      "  mne.viz.plot_projs_topomap(projs_ecg, info=epochs.info);\n",
      "/var/folders/5t/zzrvvsdd03721w2g_3y4w8xh0000gn/T/ipykernel_6486/178739447.py:3: RuntimeWarning: (X, Y) fit (3.1, 32.2) more than 20 mm from head frame origin\n",
      "  mne.viz.plot_projs_topomap(projs_ecg, info=epochs.info);\n"
     ]
    }
   ],
   "source": [
    "projs_ecg, _ = mne.preprocessing.compute_proj_ecg(\n",
    "    raw, n_mag=3, n_grad=3, n_eeg=3, average=True)\n",
    "mne.viz.plot_projs_topomap(projs_ecg, info=epochs.info);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        \n",
       "        <td>face/famous/first: 25<br/>face/famous/immediate: 10<br/>face/famous/long: 14<br/>face/unfamiliar/first: 25<br/>face/unfamiliar/immediate: 12<br/>face/unfamiliar/long: 10<br/>scrambled/first: 25<br/>scrambled/immediate: 14<br/>scrambled/long: 11</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>-0.500  2.000 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>-0.200  0.000 sec</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Epochs |  146 events (good & bad), -0.5 - 2 sec, baseline -0.2  0 sec, ~7.0 MB, data not loaded,\n",
       " 'face/famous/first': 25\n",
       " 'face/famous/immediate': 10\n",
       " 'face/famous/long': 14\n",
       " 'face/unfamiliar/first': 25\n",
       " 'face/unfamiliar/immediate': 12\n",
       " 'face/unfamiliar/long': 10\n",
       " 'scrambled/first': 25\n",
       " 'scrambled/immediate': 14\n",
       " 'scrambled/long': 11>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's see how that would theoretically improve data preservation\n",
    "reject2 = dict(mag=reject['mag'], grad=reject['grad']) \n",
    "\n",
    "epochs_clean = mne.Epochs(raw, events, event_id, tmin, tmax, proj=False,\n",
    "                          picks=picks, baseline=baseline,\n",
    "                          preload=False,\n",
    "                          reject=reject2)\n",
    "\n",
    "epochs_clean.add_proj(projs_eog + projs_ecg)\n",
    "#epochs_clean.copy().apply_proj().average().plot(spatial_colors=True);  # apply projs on a copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5t/zzrvvsdd03721w2g_3y4w8xh0000gn/T/ipykernel_6486/345308816.py:1: RuntimeWarning: (X, Y) fit (3.1, 32.2) more than 20 mm from head frame origin\n",
      "  epochs_clean.copy().average().plot(proj='interactive', spatial_colors=True);  # apply projs on a copy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/brittawe/miniforge3/envs/mne3d/lib/python3.10/site-packages/matplotlib/cbook/__init__.py\", line 307, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"/Users/brittawe/miniforge3/envs/mne3d/lib/python3.10/site-packages/matplotlib/widgets.py\", line 1097, in <lambda>\n",
      "    return self._observers.connect('clicked', lambda text: func(text))\n",
      "  File \"/Users/brittawe/Documents/code_dev/mnepython/mne/viz/utils.py\", line 372, in _toggle_proj\n",
      "    params['plot_update_proj_callback'](params, bools)\n",
      "  File \"/Users/brittawe/Documents/code_dev/mnepython/mne/viz/evoked.py\", line 1098, in _plot_update_evoked\n",
      "    new_evoked.info['projs'] = []\n",
      "  File \"/Users/brittawe/Documents/code_dev/mnepython/mne/io/meas_info.py\", line 883, in __setitem__\n",
      "    raise RuntimeError(self._attributes[key])\n",
      "RuntimeError: projs cannot be set directly. Please use methods inst.add_proj() and inst.del_proj() instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brittawe/miniforge3/envs/mne3d/lib/python3.10/site-packages/matplotlib/cbook/__init__.py\", line 307, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"/Users/brittawe/miniforge3/envs/mne3d/lib/python3.10/site-packages/matplotlib/widgets.py\", line 1097, in <lambda>\n",
      "    return self._observers.connect('clicked', lambda text: func(text))\n",
      "  File \"/Users/brittawe/Documents/code_dev/mnepython/mne/viz/utils.py\", line 372, in _toggle_proj\n",
      "    params['plot_update_proj_callback'](params, bools)\n",
      "  File \"/Users/brittawe/Documents/code_dev/mnepython/mne/viz/evoked.py\", line 1098, in _plot_update_evoked\n",
      "    new_evoked.info['projs'] = []\n",
      "  File \"/Users/brittawe/Documents/code_dev/mnepython/mne/io/meas_info.py\", line 883, in __setitem__\n",
      "    raise RuntimeError(self._attributes[key])\n",
      "RuntimeError: projs cannot be set directly. Please use methods inst.add_proj() and inst.del_proj() instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brittawe/miniforge3/envs/mne3d/lib/python3.10/site-packages/matplotlib/cbook/__init__.py\", line 307, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"/Users/brittawe/miniforge3/envs/mne3d/lib/python3.10/site-packages/matplotlib/widgets.py\", line 220, in <lambda>\n",
      "    return self._observers.connect('clicked', lambda event: func(event))\n",
      "  File \"/Users/brittawe/Documents/code_dev/mnepython/mne/viz/utils.py\", line 372, in _toggle_proj\n",
      "    params['plot_update_proj_callback'](params, bools)\n",
      "  File \"/Users/brittawe/Documents/code_dev/mnepython/mne/viz/evoked.py\", line 1098, in _plot_update_evoked\n",
      "    new_evoked.info['projs'] = []\n",
      "  File \"/Users/brittawe/Documents/code_dev/mnepython/mne/io/meas_info.py\", line 883, in __setitem__\n",
      "    raise RuntimeError(self._attributes[key])\n",
      "RuntimeError: projs cannot be set directly. Please use methods inst.add_proj() and inst.del_proj() instead.\n"
     ]
    }
   ],
   "source": [
    "epochs_clean.copy().average().plot(proj='interactive', spatial_colors=True);  # apply projs on a copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we keep all trials, probably we also removed some good signals.\n",
    "we will postpone the selection of SSP vectors to later study the impact on\n",
    "source localization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>REMARK</b>:\n",
    "     <ul>\n",
    "    <li>MNE keeps SSP projections inside the info and allows to apply them later.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's overwrite\n",
    "epochs = epochs_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Exercise</b>:\n",
    "     <ul>\n",
    "    <li>Use ICA instead of SSP to remove artifacts</li>\n",
    "    <li>What are potential benefits or disadvantages?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization Epochs\n",
    "\n",
    "See [this page](https://mne.tools/stable/auto_tutorials/epochs/plot_visualize_epochs.html) for options on how to visualize epochs.\n",
    "\n",
    "Here is just an illustration to make a so-called ERP/ERF image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot_psd(fmax=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.plot_image(picks='EEG065', sigma=1.);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The epochs object is your MNE swiss army knife for processing segmented data!\n",
    "\n",
    "- specialized methods for diagnostic plotting of data\n",
    "- averaging\n",
    "- saving\n",
    "- manipulating data, e.g., rearranging or deleting single trials, resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Exercise</b>:\n",
    "     <ul>\n",
    "    <li>How could you get the epochs corresponding to face?</li>\n",
    "    <li>How could you get the epochs corresponding to a familiar face?</li>\n",
    "    <li>How could you get the epochs corresponding to a scrambled face?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'face/famous/first': 5,\n",
       " 'face/famous/immediate': 6,\n",
       " 'face/famous/long': 7,\n",
       " 'face/unfamiliar/first': 13,\n",
       " 'face/unfamiliar/immediate': 14,\n",
       " 'face/unfamiliar/long': 15,\n",
       " 'scrambled/first': 17,\n",
       " 'scrambled/immediate': 18,\n",
       " 'scrambled/long': 19}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs.event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Epochs  |   97 events (all good), -0.5 - 2 sec, baseline [-0.2, 0], ~7.6 MB, data not loaded,\n",
       " 'face/unfamiliar/first': 25\n",
       " 'face/unfamiliar/immediate': 12\n",
       " 'face/unfamiliar/long': 10\n",
       " 'scrambled/first': 25\n",
       " 'scrambled/immediate': 14\n",
       " 'scrambled/long': 11>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs[['unfamiliar', 'scrambled']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic IO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard scenario is saving the epochs into .fif file together with all the header data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/claire/work/data/ds000117-practical/derivatives/meg_derivatives/sub-01/ses-meg/meg/sub-01_ses-meg_task-facerecognition_run-01_proc-sss-epo.fif'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_fname = raw_fname.replace('_meg.fif', '-epo.fif')\n",
    "epochs_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Loading data for 1 events and 751 original time points ...\n",
      "Loading data for 145 events and 751 original time points ...\n"
     ]
    }
   ],
   "source": [
    "epochs.save(epochs_fname, overwrite=True)  # note that epochs are save in files ending with -epo.fif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145, 378, 751)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = epochs.get_data()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scipy also supports reading and writing of matlab files. You can save your single trials with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145, 378, 751)\n"
     ]
    }
   ],
   "source": [
    "from scipy import io\n",
    "epochs_data = epochs.get_data()\n",
    "print(epochs_data.shape)\n",
    "io.savemat('epochs_data.mat', dict(epochs_data=epochs_data),\n",
    "           oned_as='row')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average the epochs to get ERF/ERP and plot it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Evoked  |  '0.17 * face/famous/first + 0.07 * face/famous/immediate + 0.10 * face/famous/long + 0.17 * face/unfamiliar/first + 0.08 * face/unfamiliar/immediate + 0.07 * face/unfamiliar/long + 0.17 * scrambled/first + 0.10 * scrambled/immediate + 0.08 * scrambled/long' (average, N=145), [-0.5, 2] sec, 376 ch, ~9.6 MB>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# refresh evoked\n",
    "evoked = epochs.average()\n",
    "evoked.del_proj()  # delete previous proj\n",
    "# take first for each sensor type\n",
    "evoked.add_proj(projs_eog[::3] + projs_ecg[::3])\n",
    "evoked.apply_proj()  # apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Evoked  |  '0.17 * face/famous/first + 0.07 * face/famous/immediate + 0.10 * face/famous/long + 0.17 * face/unfamiliar/first + 0.08 * face/unfamiliar/immediate + 0.07 * face/unfamiliar/long + 0.17 * scrambled/first + 0.10 * scrambled/immediate + 0.08 * scrambled/long' (average, N=145), [-0.5, 2] sec, 376 ch, ~9.6 MB>\n"
     ]
    }
   ],
   "source": [
    "#evoked = epochs.average()\n",
    "print(evoked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "evoked.plot(proj=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also show sensor position as line color:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked.plot(spatial_colors=True, proj=True);  # note the legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [0.0, 0.1, 0.18]\n",
    "evoked.plot_topomap(ch_type='mag', times=times, proj=True);\n",
    "evoked.plot_topomap(ch_type='grad', times=times, proj=True);\n",
    "evoked.plot_topomap(ch_type='eeg', times=times, proj=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# pure topography plots called topomap in the MNE jargon\n",
    "for ch_type in ('mag', 'grad', 'eeg'):\n",
    "    evoked.plot_topomap(times=np.linspace(0.05, 0.45, 8),\n",
    "                        ch_type=ch_type, proj=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Exercise</b>:\n",
    "     <ul>\n",
    "    <li>How does SSP impact the evoked responses? Use proj=\"interactive\" to explore</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, let's say that we want to keep the first projs for now\n",
    "\n",
    "# refresh evoked\n",
    "evoked = epochs.average()\n",
    "evoked.del_proj()  # delete previous proj\n",
    "# take first for each sensor type\n",
    "evoked.add_proj(projs_eog[::3] + projs_ecg[::3])\n",
    "evoked.apply_proj()  # apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topoplot and time series can also be shown in one single plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked.plot_joint(times=[0.17]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing and indexing epochs by condition\n",
    "\n",
    "Epochs can be indexed by integers or slices to select a subset of epochs but also with strings to select by conditions `epochs[condition]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Epochs  |   1 events (all good), -0.5 - 2 sec, baseline [-0.2, 0], ~7.6 MB, data not loaded,\n",
       " 'face/unfamiliar/first': 1>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs[0]  # first epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Epochs  |   10 events (all good), -0.5 - 2 sec, baseline [-0.2, 0], ~7.6 MB, data not loaded,\n",
       " 'face/famous/first': 3\n",
       " 'face/unfamiliar/first': 4\n",
       " 'face/unfamiliar/immediate': 1\n",
       " 'face/unfamiliar/long': 1\n",
       " 'scrambled/first': 1>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs[:10]  # first 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Epochs  |   95 events (all good), -0.5 - 2 sec, baseline [-0.2, 0], ~7.6 MB, data not loaded,\n",
       " 'face/famous/first': 24\n",
       " 'face/famous/immediate': 10\n",
       " 'face/famous/long': 14\n",
       " 'face/unfamiliar/first': 25\n",
       " 'face/unfamiliar/immediate': 12\n",
       " 'face/unfamiliar/long': 10>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs['face']  # epochs for a face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In event_id, \"/\" selects conditions in a hierarchical way, e.g. here, \"face\" vs. \"scrambled\", \"famous\" vs. \"unfamiliar\", and MNE can select them individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs['face'].average().\\\n",
    "    pick_types(meg='grad').crop(-0.1, 0.25).plot(spatial_colors=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply this to visualize all the conditions in `event_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "for condition in ['face', 'scrambled']:\n",
    "    epochs[condition].average().plot_topomap(times=[0.1, 0.15], title=condition);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write evoked data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/claire/work/data/ds000117-practical/derivatives/meg_derivatives/sub-01/ses-meg/meg/sub-01_ses-meg_task-facerecognition_run-01_proc-sss-ave.fif'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evoked_fname = raw_fname.replace('_meg.fif', '-ave.fif')\n",
    "evoked_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked.save(evoked_fname)  # note that the file for evoked ends with -ave.fif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or to write multiple conditions in 1 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "evokeds_list = [epochs[k].average() for k in event_id]  # get evokeds\n",
    "mne.write_evokeds(evoked_fname, evokeds_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading evoked from disk\n",
    "\n",
    "It is also possible to read evoked data stored in a fif file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "evokeds_list = mne.read_evokeds(evoked_fname, baseline=(None, 0), proj=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or give the explicit name of the averaged condition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked1 = mne.read_evokeds(evoked_fname, condition=\"face/famous/first\",\n",
    "                           baseline=(None, 0), proj=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** Did you notice that you can apply some preprocessing on reading the evokeds from disk?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute a contrast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked_face = epochs['face'].average()\n",
    "evoked_scrambled = epochs['scrambled'].average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast = mne.combine_evoked([evoked_face, evoked_scrambled], [0.5, -0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this combines evokeds taking into account the number of averaged epochs (to scale the noise variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "131.03448275862067\n"
     ]
    }
   ],
   "source": [
    "print(evoked1.nave)  # average of 12 epochs\n",
    "print(contrast.nave)  # average of 116 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Evoked  |  '0.500 * 0.25 * face/famous/first + 0.11 * face/famous/immediate + 0.15 * face/famous/long + 0.26 * face/unfamiliar/first + 0.13 * face/unfamiliar/immediate + 0.11 * face/unfamiliar/long + -0.500 * 0.50 * scrambled/first + 0.28 * scrambled/immediate + 0.22 * scrambled/long' (average, N=131.03448275862067), [-0.5, 2] sec, 376 ch, ~9.8 MB>\n"
     ]
    }
   ],
   "source": [
    "print(contrast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = contrast.copy().pick('grad').crop(-0.1, 0.3).plot_joint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Evoked  |  '0.25 * face/famous/first + 0.11 * face/famous/immediate + 0.15 * face/famous/long + 0.26 * face/unfamiliar/first + 0.13 * face/unfamiliar/immediate + 0.11 * face/unfamiliar/long' (average, N=95), [-0.5, 2] sec, 376 ch, ~9.8 MB>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evoked_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Evoked  |  '0.50 * scrambled/first + 0.28 * scrambled/immediate + 0.22 * scrambled/long' (average, N=50), [-0.5, 2] sec, 376 ch, ~9.8 MB>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evoked_scrambled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save your figure as pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import numpy as np\n",
    "contrast.plot_topomap(times=np.linspace(0.05, 0.15, 5), ch_type='mag')\n",
    "plt.savefig('toto.pdf')\n",
    "!open toto.pdf  # works only on a mac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>:\n",
    "     <ul>\n",
    "      <li>Compute the evoked data for 'famous', 'unfamiliar', 'scrambled' faces</li>\n",
    "      <li>Crop the data between -0.2s and 0.4s</li>     \n",
    "      <li>Plot the channel EEG065 in all 3 conditions using mne.viz.plot_compare_evokeds function</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "See: https://mne.tools/stable/generated/mne.viz.plot_compare_evokeds.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked_famous = epochs['famous'].average().crop(-0.1, 0.4)\n",
    "evoked_scrambled = epochs['scrambled'].average().crop(-0.1, 0.4)\n",
    "evoked_unfamiliar = epochs['unfamiliar'].average().crop(-0.1, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "mne.viz.plot_evoked_topo([evoked_famous, evoked_scrambled, evoked_unfamiliar]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evokeds = {k:epochs[k].average().crop(-0.1, 0.4)\n",
    "           for k in ['famous', 'unfamiliar', 'scrambled']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "mne.viz.plot_compare_evokeds(evokeds, picks='EEG065');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADVANCED: Customize your plots\n",
    "\n",
    "Want to have every text in blue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "fig = evoked1.plot(show=False)  # butterfly plots\n",
    "fig.subplots_adjust(hspace=1.0)\n",
    "for text in fig.findobj(mpl.text.Text):\n",
    "    text.set_fontsize(18)\n",
    "    text.set_color('blue')\n",
    "for ax in fig.get_axes():\n",
    "    ax.axvline(0., color='red', linestyle='--')\n",
    "plt.tight_layout()\n",
    "fig.savefig('plot_erf.pdf');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Exercise</b>:\n",
    "     <ul>\n",
    "    <li>Plot the 10 first seconds of stimulation channel just using matplotlib.</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "Tips:\n",
    "\n",
    "- Pick the stim channel using `mne.pick_types`\n",
    "- Get the data for this channel\n",
    "- Plot it using `plt.plot`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('mne3d')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "c9a20badf1778e7d20af33a09e119d2d373139c1d8ec7177610bbf7afa2db5e2"
   }
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
